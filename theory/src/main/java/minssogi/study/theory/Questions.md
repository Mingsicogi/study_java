Q1. 자바의 모든 클래스는 Object 클래스를 상속받습니다. 그리고 Object클래스에는 equals() 와 hashCode() 라는 메소드가 선언되어 있습니다. 이 메소드들은 각각 어떤 역할일까요? 이 둘의 차이점은 무엇일까요?
A1. equals()는 객체의 동등성을 비교하는 메소드이고, hashCode()는 객체의 동일성을 비교하는 메소드입니다. equals()는 두 객체의 내용이 같은지 비교하고, hashCode()는 두 객체의 주소값이 같은지 비교합니다. hashCode()는 객체를 HashMap의 key로 사용할 때 사용합니다.

Q1-1. "hashCode" 를 잘못 오버라이딩하면 "HashMap" 등 hash 콜렉션의 성능이 떨어질 수가 있습니다. 어떤 케이스일 때 그럴 수 있을까요?
A1-1. hashCode 값이 계속 중복되게 만들어지는 경우 성능이 떨어질 수 있습니다. 예를 들어, "hashCode"를 오버라이딩 하지 않고, "String"의 "hashCode"를 사용하면, 문자열의 길이가 길어질수록 hashCode 값이 중복될 확률이 높아집니다.

Q1-1-1. "HashMap"은 내부적으로 어떻게 구현되어있길래 그렇게 빨리 값을 탐색할 수 있을까요?
A1-1-1. key 값을 기반으로 hashCode값을 만들고 hashCode값을 기반으로 배열의 인덱스를 찾습니다. 그리고 해당 인덱스에 저장된 LinkedList를 순회하면서 key값을 비교합니다.

Q1-1-1-1. 기존 "HashMap" 의 시간복잡도는 얼마이고, "hashCode" 를 잘못 오버라이딩 했을때의 시간복잡도는 얼마일까요?
A1-1-1-1. 기존 "HashMap"의 시간복잡도는 O(1)이고, "hashCode"를 잘못 오버라이딩 했을때의 시간복잡도는 O(n)입니다.



Q2. StringBuilder와 StringBuffer의 차이는 무엇일까요?
A2. StringBuilder는 동기화를 지원하지 않고, StringBuffer는 동기화를 지원합니다. 동기화를 지원하지 않기 때문에 StringBuilder의 성능이 더 좋습니다.

Q2-1. 왜 동기화(synchronized)가 걸려있으면 느린걸까요?
A2-1. 동기화가 걸려있으면, 한 스레드가 동기화 블록에 진입하면 다른 스레드는 해당 블록에 진입할 수 없습니다. 그래서 동기화가 걸려있으면 느린 것입니다.

Q2-1-1. 싱글 스레드로 접근한다는 가정하에선 "StringBuilder" 와 "StringBuffer" 의 성능이 똑같을까요?
A2-1-1. 싱글 스레드로 접근한다는 가정하에선 "StringBuilder" 와 "StringBuffer" 의 성능이 똑같습니다.




Q3. System.out.println 메소드는 현업에서 절대 쓰지 말라고하는 메소드인데요. 그 이유가 무엇일까요?
A3. System.out.println 메소드는 내부적으로 synchronized 키워드를 사용하고 있습니다. 그리고 synchronized 키워드는 Blocking IO를 사용하고 있습니다. 그래서 현업에서 절대 쓰지 말라고 하는 메소드입니다.

Q3-1. synchronized 키워드는 왜 현업에서 큰 성능 저하를 일으킬 수 있을까요?
A3-1. synchronized 키워드는 내부적으로 Lock을 사용합니다. 그래서 Lock을 사용하면서 성능 저하를 일으킬 수 있습니다.

Q3-2. Blocking IO는 왜 성능을 저하시킬 수 있을까요?
A3-2. Blocking IO는 내부적으로 Lock을 사용합니다. 그래서 Lock을 사용하면서 성능 저하를 일으킬 수 있습니다.

Q3-3. synchronized 가 Blocking IO 와 만나면 어떻게 환장의 성능하락을 만들 수 있는걸까요?
A3-3. synchronized 가 Blocking IO 와 만나면, Lock을 사용하면서 성능 저하를 일으킬 수 있습니다.

Q3-3-1. 이 두 개가 만났을 때 스레드가 어떻게 동작할지, CPU 사용률은 어떻게 될지 시뮬레이션을 해보세요.





Q4. ArrayList 는 내부적으로 어떻게 구현되어있을까요?
A4. ArrayList 는 내부적으로 배열로 구현되어있습니다.

Q4-1. 배열로 구현되어있다면 분명 크기가 꽉 차면 일반 배열처럼 예외가 발생할텐데 ArrayList 는 어떻게 무한히 데이터를 받을 수 있을까요?
A4-1. ArrayList 는 내부적으로 배열로 구현되어있습니다. 그래서 배열로 구현되어있기 때문에 크기가 꽉 차면 예외가 발생합니다. 무한히 데이터를 받을 수 없습니다.




Q5. 스레드는 왜 써야하는 것일까요?
A5. 스레드는 동시에 여러 일을 처리할 수 있기 때문에 써야합니다.

Q5-1. 스레드를 쓰면 동시에 여러 일을 처리할 수 있으니 한 1만개정도 띄우면 너무 좋지 않을까요?
A5-1. 스레드도 Computer Resource 를 사용하기 때문에, 너무 많이 띄우면 성능이 저하됩니다. thread 하나당 대략 1MB 정도의 메모리를 사용합니다. JVM 에서 사용하는 heap 영역 메모리와는 별개입니다.

Q5-1-1. 사실 좋지 않은데.. 왜 좋지 않을까요? 스레드를 사용하는데에 있어 어떤 비용이 들까요?
A5-1-1. 좋지 않지 않습니다. 객체 지향적인 프로그래밍을 하기 위해서는 객체 각자에서 할 일을 독립적으로 수행할 수 있어야합니다. 때문에 스레드를 사용하는데에는 비용이 들지만, 객체 지향적인 프로그래밍을 하기 위해서는 필수적입니다.

Q5-1-1-1. 메모리 양은 얼마나 들까요?
A5-1-1-1. A5-1 답변을 참고해주세요.

Q5-1-1-1-1. 컨텍스트 스위칭은 비용이 얼마나 들까요? CPU 사이클 단위로 말씀해주세요.
A5-1-1-1-1. 컨텍스트 스위칭은 CPU 사이클 단위로 비용이 듭니다. 컨텍스트 스위칭이란, CPU 를 사용하던 프로세스가 CPU 를 양보하고 다른 프로세스가 CPU 를 사용할 수 있도록 하는 것을 말합니다. 컨텍스트 스위칭이 발생하면, CPU 를 사용하던 프로세스의 상태를 저장하고, 다른 프로세스의 상태를 불러와야합니다.




Q6. 0이 들어있는 변수에 10개의 스레드가 동시에 접근해서 ++ 연산을 하면 우리 예상과 다르게 10이 나오지 않습니다. 왜 그럴까요?
A6. ++ 연산은 3가지의 동작으로 이루어져 있습니다. 
1. 변수의 값을 읽어온다.
2. 변수의 값을 1 증가시킨다. 
3. 변수에 값을 저장한다. 
이 3가지 동작이 동시에 일어나면, 1번과 3번이 동시에 일어나면서 2번이 누락되는 경우가 발생합니다. 

Q6-1. ++ 연산은 구체적으로 어떤 행위들로 이루어져 있을까요?
A6-1. A6 답변을 참고해주세요.


Q6-1-1. 이 문제를 해결하려면 어떻게 해야할까요?
A6-1-1. 이 문제를 해결하기 위해서는, Atomic 연산을 사용해야합니다. Atomic 연산은 하나의 연산으로 처리되는 연산을 말합니다. Atomic 연산은 하나의 연산으로 처리되기 때문에, 1번과 3번이 동시에 일어나지 않습니다.




Q7. 자바에서 동시성과 관련된 예약어를 모두 말씀해주세요.
A7. volatile, synchronized

Q7-1. volatile 키워드는 어떤 키워드일까요?
A7-1. volatile 키워드는 CPU에서 값을 캐시에서 읽어오지 않고, 메인 메모리에서 읽어오는 키워드입니다.

Q7-1-1. 이 키워드는 가시성을 보장해준다고 하는데, 이게 어떤 말일까요?
A7-1-1. 가시성을 보장해준다는 말은, 한 스레드에서 값을 변경하면, 다른 스레드에서도 변경된 값을 볼 수 있다는 말입니다.

Q7-2. synchronized 키워드는 어떤 키워드일까요?(민석이 추가 질문)
A7-2. synchronized 키워드는 한 스레드가 해당 메소드를 실행하고 있을 때, 다른 스레드가 해당 메소드를 실행하지 못하도록 하는 키워드입니다.



Q8. Blocking IO와 Non-Blocking IO 의 차이를 말씀해주세요.
A8. Blocking IO는 IO 작업이 끝날 때까지 기다리는 IO 작업이고, Non-Blocking IO는 IO 작업이 끝나지 않아도 다음 작업을 수행하는 IO 작업입니다.

Q8-1. Blocking IO 가 일어나면 스레드에는 무슨 일이 생길까요?
A8-1. Blocking IO 가 일어나면 스레드는 기다리는 상태가 되고, CPU 를 사용하지 않습니다.

Q8-1-1. 스레드가 멈춰있는 동안 CPU는 어떻게 될까요?
A8-1-1. 스레드가 멈춰있는 동안 CPU는 다른 스레드를 실행시킬 수 있습니다.

Q8-1-1-1. CPU가 쉬는 것을 막으려면 어떻게 해야할까요?
A8-1-1-1. CPU가 쉬는 것을 막으려면 스레드를 늘리면 됩니다.

Q8-1-1-1-1. 스레드를 늘리면 단점이 무엇일까요?
A8-1-1-1-1. 스레드를 늘리면 메모리를 더 사용하게 됩니다.

Q8-1-1-1-1-1. Non-Blocking IO는 CPU 활용률이 어떨까요?
A8-1-1-1-1-1. Non-Blocking IO는 Thread 를 쉬는 상태로 만들지 않고 계속적으로 일을 할 수 있습니다. 예를 들어, Netty 의 NIO는 request가 들어와 service 로직에 작업 요청을 하고, 응답을 기다리지 않고 request를 받을 수 있습니다. 이렇게 되면, CPU 를 더 타이트하게 사용할 수 있습니다.



Q9. Serializable 은 무엇일까요?
A9. Serializable 은 객체를 직렬화할 수 있게 해주는 인터페이스입니다.

Q9-1. 직렬화란 무엇인가요?
A9-1. 직렬화란 객체를 바이트 배열로 변환하는 것을 말합니다.

Q9-1-1. 직렬화의 포맷엔 무엇무엇이 있을까요?
A9-1-1. 직렬화의 포맷엔 Java, JSON, XML 등이 있습니다.





Q10. GC란 무엇이고, 왜 써야할까요?
A10. GC란 Garbage Collector의 약자로, 메모리를 관리해주는 역할을 합니다. GC를 사용하지 않으면, 메모리를 직접 관리해야 합니다. 이는 개발자가 메모리를 관리하는데 많은 시간을 써야하고, 실수할 가능성이 높습니다. 그래서 GC를 사용하면, 개발자가 메모리를 신경쓰지 않아도 되고, 메모리를 관리하는데 많은 시간을 쓰지 않아도 됩니다.

Q10-1. 개발자가 메모리에 대해 신경을 덜 쓸 수 있어서 편해지는데, 그에 따른 단점은 없을까요?
A10-1. 아무래도 GC에서 하는 메모리 관리는 메모리에 저장된 전체 데이터를 주기적으로 확인해가면서 처리하기 때문에 개발자가 직접하는것과 효율적인 측면에서 차이가 있습니다.

Q10-1-1. 개발자가 GC 튜닝을 하는 궁극적인 목표는 무엇일까요?
A10-1-1. GC 튜닝을 하는 궁극적인 목표는 GC가 발생하는 횟수를 줄이는 것입니다. GC가 발생하는 횟수를 줄이면, GC가 발생하는 시간도 줄어들기 때문입니다.

Q10-1-2. G1GC부터는 GC튜닝에 크게 손이 가진 않는데, G1GC는 어떻게 만들었길래 개발자가 튜닝을 이전보다 덜 해도 되는걸까요?
A10-1-2. A10-1-1에 답변한것처럼 GC튜닝의 목적은 GC 발생횟수를 줄이기 위함입니다. G1GC는 GC가 발생하는 시간을 줄이기 위해, GC가 발생하는 영역을 여러 영역으로 나누어서 GC를 진행합니다. 이렇게 하면, GC가 발생하는 시간을 줄일 수 있습니다.

---- 리전으로 구성된 구조가 왜 튜닝의 수고를 덜어주는걸까요?




Q11. 잘 운영하고 있던 어플리케이션이 갑자기 Out of Memory Error(OOM)를 내며 프로세스가 종료되었습니다. 어떻게 대처해볼 수 있을까요?
A11. 먼저 JVM의 -XX:+HeapDumpOnOutOfMemoryError 옵션과 -XX:NativeMemoryTracking=summary or -XX:NativeMemoryTracking=detail 옵션을 활성화하여, application 을 재시작하고, 
heap dump 파일과 native memory tracking 파일을 생성합니다.(jcmd 명령어를 사용하여, jcmd <pid> VM.native_memory detail 명령어를 사용하여, native memory tracking 파일을 생성할 수 있습니다.)


Q11-1. OOM의 원인은 어떻게 파악해볼 수 있을까요?
A11-1. https://heaphero.io/ 또는 https://www.ej-technologies.com/products/jprofiler/overview.html 를 사용하여, heap dump 파일을 분석합니다.

Q11-1-1. OOM의 원인을 로그만 가지고 파악하는게 가능할까요?
A11-1-1. 메모리 여러 영역을 확인해야합니다. 단순히 heap 영역으로만 메모리를 사용하고 있지 않습니다. native memory, direct memory, off-heap memory 등이 있습니다.

Q11-1-1-1. 힙 덤프란 무엇인가요?
A11-1-1-1. 힙 덤프는 JVM이 사용하는 메모리 영역 중 힙 영역의 상태를 파일로 저장한 것입니다.

Q11-1-1-1-1. 힙 덤프는 어떻게 생성할 수 있을까요?
A11-1-1-1-1. -XX:+HeapDumpOnOutOfMemoryError 옵션을 사용하여, OOM이 발생하면 자동으로 힙 덤프를 생성할 수 있습니다. 또는 jcmd 를 사용해서 덤프 파일을 만들 수 있습니다. arthas 를 사용해서도 덤프 파일을 만들 수 있습니다.

Q11-1-1-1-1-1. 첫 질문으로 돌아가자면 운영중인 어플리케이션이 갑작스럽게 종료된건데, 어플리케이션이 종료된 상태에서 힙덤프를 생성하는게 가능한가요?
A11-1-1-1-1-1. 위 A11-1-1-1. 답변을 참고해주세요




Q12. 서비스를 운영하면 모니터링을 해야할 일이 많은데 어떤 툴들을 사용해볼 수 있을까요?
A12. Pinpoint, Newrelic, Datadog

Q12-1. Pinpoint, Newrelic, Datadog 같은 APM 툴들은 한 요청에 대한 매우 세밀한 트래킹을 제공합니다. 어떤 원리로 구현한걸까요?
A12-1. ASM 을 사용해 구현되었습니다.

Q12-1-1. APM툴을 쓸때 JVM의 javaagent라는 옵션을 사용하는데 이것은 무엇일까요?
A12-1-1. JVM 내에서 main 메소드 진입 전 시점에서 특정 행위를 할 수 있는 java agent class 를 로드하는 옵션입니다.

A12-1-1-1. Java Bytecode Instrumentaion이란 무엇일까요?
Q12-1-1-1. 

Q12-1-1-2. 이 기술에서 자바의 바이트코드를 순회하기 위해 어떤 디자인 패턴을 사용할까요?
visitor pattern

-- JMX 란 무엇일까요?

--- JMX를 활용하여 모니터링 할 수 있는 도구는 무엇무엇이 있을까요?




Q13. JIT 컴파일러란 무엇이고, 이것은 왜 필요할까요?
A13. JIT 컴파일러는 자바 바이트코드를 기계어로 바꾸는 컴파일러입니다. JIT 컴파일러는 자바 바이트코드를 기계어로 바꾸는 과정에서 최적화를 수행합니다. 이 최적화를 통해 성능을 향상시킬 수 있습니다.

Q13-1. AOT 컴파일은 무엇일까요?
A13-1. AOT 컴파일은 Ahead Of Time Compile의 약자로, 컴파일 시점이 런타임 이전이라는 점에서 JIT 컴파일과 다릅니다. AOT 컴파일은 컴파일 시점에 바이트코드를 기계어로 바꾸는 방식입니다. AOT 컴파일은 JIT 컴파일과 달리 최적화를 수행하지 않습니다. 
AOT 컴파일은 컴파일 시점에 바이트코드를 기계어로 바꾸기 때문에 런타임에 바이트코드를 기계어로 바꾸는 과정이 필요없습니다. 따라서 AOT 컴파일은 JIT 컴파일에 비해 빠르지만, 최적화를 수행하지 않기 때문에 성능이 떨어질 수 있습니다.

Q13-2. C1 컴파일러와 C2 컴파일러는 무엇일까요?
A13-2. C1 컴파일러는 Client Compiler의 약자로, 클라이언트 환경에서 사용되는 JIT 컴파일러입니다. C1 컴파일러는 최적화를 수행하지 않습니다. C1 컴파일러는 런타임에 바이트코드를 기계어로 바꾸는 과정에서 최적화를 수행하지 않기 때문에 성능이 떨어질 수 있습니다.


--- 이 2개는 역할이 어떻게 다른가요?

-- 컴파일 과정에서 컴파일러가 최적화해주는 것들은 무엇무엇이 있을까요?




Q14. 힙에 메모리를 할당하는 과정에서 어떤 일들이 벌어지나요?
A14. 

Q14-1. TLAB이란 무엇일까요?
A14-1. TLAB은 Thread Local Allocation Buffer의 약자로, 스레드마다 할당된 메모리 공간입니다. 따라서 TLAB을 사용하면 스레드 간 메모리 공간을 공유하지 않기 때문에 메모리 공간을 공유하지 않아도 되기 때문에 성능이 향상됩니다.

Q14-1-1. 이것은 어떤 문제를 해결하기 위해 만들어진 것일까요?
A14-1-1. 각각의 스레드마다 고유한 정보를 저장하기 위해 만들어졌습니다.